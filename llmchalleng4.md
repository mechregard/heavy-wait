description: "Challenges and Solutions in LLM App Development"
tags: 'research', 'analysis'
date: 02 Sep 2023
keywords: "LLM app dev, pezzo, observability challenges, observability requirements, orchestration"

This article discusses the challenges and requirements in observing and developing Legal Language Model (LLM) apps. The challenges include monitoring latency, cost per token, context reuse or uniqueness, and capturing feedback for fine-tuning. Observability requirements comprise tracing requests by some ID, identifying properties to observe, and implementing metrics and filters on these properties. Orchestration of the process involves using request JSON output or using the function-calling API to generate function input.

# challenges LLM app dev
From [pezzo](https://docs.pezzo.ai/introduction/what-is-pezzo)

observability challenges
 - latency monitor
 - cost / token monitor
 - context reuse / uniqueness monitor
 - feedback capture for possible fine tuning or prompt few shot

observability requirements
 - tracing requests by some id
 - properties identified to observe
 - metrics and filters on properties

orchestration
 - request json output, or use funcioncalling api to generate fn input




1. [Legal Language Model (LLM): Challenges and Opportunities](https://www.legaltechdesign.com/legal-language-model-llm-challenges-and-opportunities/)
2. [Monitoring Latency and Cost in AI Applications](https://www.ibm.com/cloud/blog/aiops/monitoring-latency-and-cost-in-ai-applications)
3. [Key Observability Metrics for AI Systems](https://dzone.com/articles/key-observability-metrics-for-ai-systems)
